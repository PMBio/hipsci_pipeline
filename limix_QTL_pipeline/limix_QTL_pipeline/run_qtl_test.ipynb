{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import limix\n",
    "import qtl_output\n",
    "import qtl_loader_utils\n",
    "from qtl_snp_qc import do_snp_qc\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import Imputer\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##loader functions\n",
    "# def _ensure_dir(file_path):\n",
    "#     '''Check if directory exists for output, and create it if it doesn't.'''\n",
    "#     directory = os.path.dirname(file_path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "# def _get_kinship_df(kinship_filename):\n",
    "#     if kinship_filename:\n",
    "#         kinship_df = pd.read_csv(kinship_filename,sep='\\t',index_col=0)\n",
    "#     else:\n",
    "#         kinship_df = None\n",
    "#     return kinship_df\n",
    "\n",
    "# def _get_samplemapping_df(sample_mapping_filename,sample_labels,key_from):\n",
    "#     assert(key_from in ['iid','sample'])\n",
    "#     if sample_mapping_filename:\n",
    "#         mapping_df = pd.read_csv(sample_mapping_filename,sep='\\t',header=None,names=['iid','sample'])\n",
    "#         mapping_df.set_index(key_from,inplace=True)\n",
    "#     else:\n",
    "#         #assume the mapping is the identity mapping\n",
    "#         identifiers = sample_labels\n",
    "#         mapping_df = pd.DataFrame(data=identifiers,index=identifiers,columns=['sample'])\n",
    "#     return mapping_df\n",
    "\n",
    "# def _get_covariate_df(covariates_filename):\n",
    "#     if covariates_filename:\n",
    "#         covariate_df = pd.read_csv(covariates_filename,sep='\\t',index_col=0)\n",
    "#     else:\n",
    "#         covariate_df = None\n",
    "#     return covariate_df\n",
    "\n",
    "# def _get_genotype_data(geno_prefix):\n",
    "#     bim,fam,bed = limix.io.read_plink(geno_prefix,verbose=False)\n",
    "#     fam.set_index('iid',inplace=True)\n",
    "#     return bim,fam,bed\n",
    "\n",
    "# def _get_annotation_df(anno_filename):\n",
    "#     annotation_col_dtypes = {'feature_id':np.object,\n",
    "#                          'gene_id':np.object,\n",
    "#                          'gene_name':np.object,\n",
    "#                          'chromosome':np.object,\n",
    "#                          'start':np.int64,\n",
    "#                          'end':np.int64,\n",
    "#                          'strand':np.object}\n",
    "#     annotation_df = pd.read_csv(anno_filename,sep='\\t',index_col=0,dtype=annotation_col_dtypes)\n",
    "#     return annotation_df\n",
    "\n",
    "# def _get_phenotype_df(pheno_filename):\n",
    "#     return pd.read_csv(pheno_filename,sep='\\t',index_col=0)\n",
    "\n",
    "# def do_snp_qc(snp_df, min_call_rate, min_maf, min_hwe_P):\n",
    "   \n",
    "#     #Determine call rate.\n",
    "#     call_rate = 1-snp_df.isnull().sum()/len(snp_df.index)\n",
    "#     #print(call_rate)\n",
    "#     #print(call_rate < min_call_rate)\n",
    "#     failed_snp_names  = list(snp_df.columns[call_rate < min_call_rate])\n",
    "#     #pass_qc_snps_all = list(snp_df.columns[call_rate >= min_call_rate])\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[call_rate >= min_call_rate])]\n",
    "\n",
    "#     #Determine MAF.\n",
    "#     genotypeCounter = np.zeros((len(snp_df.columns),3))\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         for sample in range(0, len(snp_df.index)):\n",
    "#             if not math.isnan(snp_df.iloc[sample,snp]) :\n",
    "#                 #print(snp_df.iloc[sample,snp])\n",
    "#                 #print(i)\n",
    "#                 #print(snp)\n",
    "#                 #print(int(round(snp_df.iloc[snp,i])))\n",
    "#                 genotypeCounter[snp,int(round(snp_df.iloc[sample,snp]))] +=1\n",
    "\n",
    "#     #Here we make sure that the major allele is temporarly \"coded\" as 0.\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         if genotypeCounter[snp,0]<genotypeCounter[snp,2]:\n",
    "#             tmp = genotypeCounter[snp,0]\n",
    "#             genotypeCounter[snp,0] = genotypeCounter[snp,2]\n",
    "#             genotypeCounter[snp,2] = tmp\n",
    "\n",
    "#     #print(genotypeCounter)\n",
    "#     maf = np.zeros((len(snp_df.columns)))\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         maf[snp] = ((genotypeCounter[snp,2]*2)+genotypeCounter[snp,1])/(len(snp_df.index)*2)\n",
    "\n",
    "#     failed_snp_names.extend(list(snp_df.columns[maf < min_maf]))\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[maf >= min_maf])]    \n",
    "#     genotypeCounter = genotypeCounter[maf >= min_maf,]\n",
    "\n",
    "#     #Determine HWE.\n",
    "#     hweP = np.zeros((len(snp_df.columns)))\n",
    "\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         rare_copies = int(((genotypeCounter[snp,2])*2)+genotypeCounter[snp,1])\n",
    "#         genotypes = (genotypeCounter[snp,2]+genotypeCounter[snp,1]+genotypeCounter[snp,0])\n",
    "#         het_probs = np.ones((rare_copies+1))\n",
    "#         # start at midpoint #\n",
    "\n",
    "#         mid = int(round(rare_copies * (2 * genotypes - rare_copies) / (2 * genotypes)))\n",
    "\n",
    "#         # check to ensure that midpoint and rare alleles have same parity #\n",
    "#         if mid % 2 is not rare_copies % 2 :\n",
    "#             mid+=1\n",
    "\n",
    "#         curr_homr = (rare_copies - mid) / 2;\n",
    "#         curr_homc = genotypes - mid - curr_homr;\n",
    "#         #print(mid)\n",
    "#         #print(het_probs.shape)\n",
    "#         sum_values = het_probs[mid];\n",
    "\n",
    "#         for curr_hets in range(mid, 2, -2) :\n",
    "#             het_probs[curr_hets - 2] = het_probs[curr_hets] * curr_hets * (curr_hets - 1.0) / (4.0 * (curr_homr + 1.0) * (curr_homc + 1.0))\n",
    "#             sum_values += het_probs[curr_hets - 2]\n",
    "#             ## 2 fewer heterozygotes for next iteration -> add one rare, one common homozygote ##\n",
    "#             curr_homr+=1\n",
    "#             curr_homc+=1\n",
    "\n",
    "\n",
    "#         curr_homr = (rare_copies - mid) / 2;\n",
    "#         curr_homc = genotypes - mid - curr_homr;\n",
    "#         for curr_hets in range(mid, (int(rare_copies) - 2), 2) :\n",
    "#             het_probs[curr_hets + 2] = het_probs[curr_hets] * 4.0 * curr_homr * curr_homc / ((curr_hets + 2.0) * (curr_hets + 1.0))\n",
    "#             sum_values += het_probs[curr_hets + 2]\n",
    "#             curr_homr-=1\n",
    "#             curr_homc-=1\n",
    "\n",
    "#         p_hwe = 0.0\n",
    "#         het_probs[int(genotypeCounter[snp,1])]/= sum_values\n",
    "#         for index in range(0,int(rare_copies)) :\n",
    "#             if index != int(genotypeCounter[snp,1]) :\n",
    "#                 het_probs[index] /= sum_values\n",
    "#             if het_probs[index] <= het_probs[int(genotypeCounter[snp,1])] :\n",
    "#                 p_hwe += het_probs[index];\n",
    "\n",
    "#         hweP[snp] = 1 if p_hwe > 1.0 else p_hwe;\n",
    "\n",
    "#     failed_snp_names.extend(list(snp_df.columns[hweP < min_hwe_P]))\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[hweP >= min_hwe_P])]\n",
    "\n",
    "#     return snp_df.columns, failed_snp_names\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "pheno_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_YRI_Expr.txt.gz'\n",
    "anno_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_Annot.txt'\n",
    "geno_prefix = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Genotypes/Geuvadis'\n",
    "window_size = 250000\n",
    "min_maf = 0.05\n",
    "min_hwe_P = 0.01\n",
    "min_call_rate = 0.95\n",
    "cis_mode = True\n",
    "# cis_mode = False\n",
    "n_perm=100\n",
    "snps_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/snpFilterList.txt'\n",
    "output_dir = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/outputTest'\n",
    "chromosome='all'\n",
    "\n",
    "covariates_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_YRI_covariates.txt'\n",
    "kinship_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Genotypes/Geuvadis_chr1_kinship.txt'\n",
    "sample_mapping_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Geuvadis_CEU_gte.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 5)\n",
      "(178,)\n",
      "(178, 5)\n"
     ]
    }
   ],
   "source": [
    "# Core function to take input and run QTL tests on a given chromosome.\n",
    "#Load input data files & filter for relevant data\n",
    "\n",
    "bim,fam,bed = qtl_loader_utils.get_genotype_data(geno_prefix)\n",
    "phenotype_df = qtl_loader_utils.get_phenotype_df(pheno_filename)\n",
    "annotation_df = qtl_loader_utils.get_annotation_df(anno_filename)\n",
    "\n",
    "individual2sample_df = qtl_loader_utils.get_samplemapping_df(sample_mapping_filename,list(phenotype_df.columns),'iid')\n",
    "sample2individual_df = qtl_loader_utils.get_samplemapping_df(sample_mapping_filename,list(phenotype_df.columns),'sample')\n",
    "\n",
    "kinship_df = qtl_loader_utils.get_kinship_df(kinship_filename) \n",
    "if kinship_df is not None:\n",
    "    kinship_df = kinship_df.loc[list(set(fam.index)&set(individual2sample_df.index)),list(set(fam.index)&set(individual2sample_df.index))]\n",
    "    #Filter from individual2sample_df & sample2individual_df since we don't want to filter from the genotypes.\n",
    "    individual2sample_df = individual2sample_df.loc[kinship_df.index,:]\n",
    "    sample2individual_df = sample2individual_df[sample2individual_df['iid'].map(lambda x: x in list(map(str, kinship_df.index)))]\n",
    "    \n",
    "\n",
    "covariate_df = qtl_loader_utils.get_covariate_df(covariates_filename)\n",
    "phenotype_df = phenotype_df.loc[annotation_df.index.values,individual2sample_df.loc[list(set(fam.index)&set(individual2sample_df.index)),'sample'].values]\n",
    "if covariate_df is not None:\n",
    "    phenotype_df = phenotype_df.loc[:,covariate_df.index]\n",
    "    covariate_df = covariate_df.loc[phenotype_df.columns,:]\n",
    "snp_filter_df = qtl_loader_utils.get_snp_df(snps_filename)\n",
    "\n",
    "### make sure covariates, kinship & phenotype is not changed in a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSG00000215014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if(cis_mode):\n",
    "    #Remove features from the annotation that are on chromosomes which are not present anyway.\n",
    "    annotation_df = annotation_df[annotation_df['chromosome'].map(lambda x: x in list(set(bim['chrom'])))]\n",
    "    annotation_df = annotation_df[annotation_df['chromosome'].map(lambda x: x in list(map(str, range(1, 23))))]\n",
    "\n",
    "#Determine features to be tested\n",
    "if chromosome=='all':\n",
    "    feature_list = list(set(annotation_df.index)&set(phenotype_df.index))    \n",
    "else:\n",
    "    feature_list = list(set(annotation_df[annotation_df['chromosome']==chromosome].index)&set(phenotype_df.index))\n",
    "\n",
    "#Array to store indices of snps tested\n",
    "tested_snp_idxs = []\n",
    "\n",
    "feature_id = feature_list[1]\n",
    "print(feature_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1510355\n",
      "1511373\n",
      "22\n",
      "(0, 0)\n",
      "(90, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/software/stegle/users/mjbonder/conda-envs/limix_qtl/lib/python2.7/site-packages/dask/core.py:306: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  elif type_arg is type(key) and arg == key:\n"
     ]
    }
   ],
   "source": [
    "chrom = str(annotation_df.loc[feature_id,'chromosome'])\n",
    "print(chrom)\n",
    "start = annotation_df.loc[feature_id,'start']\n",
    "print(start)\n",
    "end = annotation_df.loc[feature_id,'end']\n",
    "print(end)\n",
    "\n",
    "#make robust to features specified back-to-front\n",
    "lowest = min([start,end])\n",
    "highest = max([start,end])\n",
    "\n",
    "if (cis_mode) : \n",
    "    snpQuery = bim.query(\"chrom == '%s' & pos > %d & pos < %d\" % (chrom, lowest-window_size, highest+window_size))\n",
    "else :\n",
    "    snpQuery = bim.query(\"(chrom == '%s' & (pos < %d | pos > %d))|chrom != '%s'\" % (chrom, lowest-window_size, highest+window_size,chrom))\n",
    "    snpQuery = snpQuery.loc[snpQuery['chrom'].map(lambda x: x in list(map(str, range(1, 23))))]\n",
    "    \n",
    "blocksize = 500\n",
    "#print(snpQuery.shape)\n",
    "if len(snpQuery) != 0 and snp_filter_df is not None:\n",
    "    snpQuery = snpQuery.loc[snpQuery['snp'].map(lambda x: x in list(map(str, snp_filter_df.index)))]\n",
    "    \n",
    "# print(len(snpQuery))\n",
    "if len(snpQuery) != 0:\n",
    "\n",
    "    print(len(snpQuery)%blocksize)\n",
    "    previous =0\n",
    "    results_df = pd.DataFrame()\n",
    "    print(results_df.shape)\n",
    "    for snpGroup in chunker(snpQuery, blocksize):\n",
    "        #Here we need to batch for cis & trans.\n",
    "        snp_idxs = snpGroup['i'].values\n",
    "        snp_names = snpGroup['snp'].values\n",
    "\n",
    "        tested_snp_idxs.extend(snp_idxs)\n",
    "\n",
    "        ##Check for NA's in feature. Remove samples with NA's\n",
    "\n",
    "        sample_ids = individual2sample_df.loc[:,'sample'].values\n",
    "\n",
    "        phenotype_ds = phenotype_df.loc[feature_id,sample_ids]\n",
    "        contains_missing_samples = any(phenotype_ds.isnull().values)\n",
    "        phenotype_ds.dropna(inplace=True)\n",
    "\n",
    "        #indices for relevant individuals in genotype matrix    \n",
    "        individual_ids = list(set(fam.index)&set(sample2individual_df.loc[phenotype_ds.index,'iid']))\n",
    "        individual_idxs = fam.loc[individual_ids,'i'].values\n",
    "\n",
    "        #subset genotype matrix, we cannot subselect at the same time, do in two steps.\n",
    "        snp_df = pd.DataFrame(data=bed[snp_idxs,:].compute().transpose(),index=fam.index,columns=snp_names)\n",
    "        snp_df = snp_df.loc[individual_ids,:]\n",
    "        print(snp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 22)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pass_qc_snps_all = []\n",
    "fail_qc_snps_all = []\n",
    "print(snp_df.shape)\n",
    "print(contains_missing_samples)\n",
    "\n",
    "#For the updated QC where we only use one individual per genotype. We can just select sites from df to test.\n",
    "if not contains_missing_samples:\n",
    "    #remove snps from snp_df if they fail QC\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[~snp_df.columns.isin(fail_qc_snps_all)]]\n",
    "    snps_to_test_df = snp_df.loc[:,snp_df.columns[~snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "    \n",
    "    #Only do QC on relevant SNPs. join pre-QCed list and new QCed list.\n",
    "    #passed_snp_names,failed_snp_names = snp_qc.do_snp_qc(snps_to_test_df)\n",
    "    #File will be called snp_qc.py\n",
    "    passed_snp_names,failed_snp_names = do_snp_qc(snps_to_test_df, min_call_rate, min_maf, min_hwe_P)\n",
    "    snps_to_test_df = None\n",
    "    \n",
    "    #append snp_names and failed_snp_names\n",
    "    pass_qc_snps_all.extend(passed_snp_names)\n",
    "    fail_qc_snps_all.extend(failed_snp_names)\n",
    "    \n",
    "    snp_names  = list(snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)])\n",
    "    #snp_names = ['snp_1_2739933', 'snp_1_2750437', 'snp_1_2752719', 'snp_1_2753372']\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "\n",
    "else:\n",
    "    #Do snp QC for relevant section.\n",
    "    passed_snp_names,failed_snp_names = do_snp_qc(snp_df, min_call_rate, min_maf, min_hwe_P)\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "    \n",
    "    \n",
    "# if len(snp_df.columns) != 0:\n",
    "#     continue\n",
    "\n",
    "snp_matrix = snp_df.values\n",
    "snp_df = None\n",
    "\n",
    "snp_matrix = Imputer(missing_values=np.nan,strategy='mean',axis=0,copy=False).fit_transform(snp_matrix)\n",
    "\n",
    "if kinship_df is not None:\n",
    "    kinship_mat = kinship_df.loc[individual_ids,individual_ids].values\n",
    "else:\n",
    "    kinship_mat = None\n",
    "\n",
    "#map individual_ids to samples\n",
    "sample_ids = individual2sample_df.loc[individual_ids,'sample'].values\n",
    "phenotype = phenotype_ds.loc[sample_ids].values\n",
    "\n",
    "#generate covariate matrix\n",
    "if covariate_df is not None:\n",
    "    cov_matrix = np.concatenate([np.ones((len(sample_ids),1)),covariate_df.loc[sample_ids,:].values],axis=1)\n",
    "else:\n",
    "    cov_matrix = None\n",
    "\n",
    "#fit modelrun\n",
    "LMM = limix.qtl.qtl_test_lmm(snp_matrix, phenotype,K=kinship_mat,covs=cov_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.49234899e-01   7.26263184e-02   1.84431507e-01   4.35895397e-02\n",
      "   1.34348460e-01   3.48686024e-01   4.84753284e-01   5.54058677e-02\n",
      "   1.04955465e-01   1.09500403e-01   3.42631715e-01   1.36650001e-01\n",
      "   4.37579682e-01   5.76479758e-03   1.02009309e-01   2.27756261e-02\n",
      "   1.06285590e-01   4.23040589e-01   5.00284759e-02   1.30340309e-01\n",
      "   5.73453548e-01   1.53682482e-01   4.90791202e-01   3.81100278e-01\n",
      "   1.45786326e-01   4.66568320e-01   1.60275463e-01   2.73222251e-01\n",
      "   9.29405803e-02   2.53443384e-01   3.47989116e-01   2.73270071e-01\n",
      "   5.82269963e-01   2.46745143e-01   4.24025544e-01   7.09441198e-02\n",
      "   1.15027178e-01   1.51215508e-02   8.73004186e-02   6.63617031e-04\n",
      "   2.24118329e-01   1.66007024e-01   3.19934638e-02   1.82391222e-01\n",
      "   4.25695212e-01   1.66419227e-01   5.72699763e-01   3.35537123e-01\n",
      "   3.52332078e-01   1.57130860e-01   6.61989660e-02   2.91029345e-01\n",
      "   4.33779207e-03   9.88973855e-02   1.72430274e-01   5.35355723e-02\n",
      "   1.40332761e-02   4.31061318e-01   2.20201007e-01   1.34286443e-01\n",
      "   1.37083053e-03   7.78497794e-01   9.91441270e-02   2.36546850e-01\n",
      "   4.81669365e-01   2.53948409e-01   3.12350362e-01   1.85088462e-01\n",
      "   2.28540364e-01   1.15400009e-01   1.42552754e-01   3.30086049e-02\n",
      "   6.88283349e-02   4.74012878e-01   4.04545248e-01   1.31708815e-02\n",
      "   3.68236745e-01   8.11712472e-02   9.01964637e-02   5.93366933e-01\n",
      "   3.10070269e-01   7.92232669e-01   3.98257284e-01   2.77732955e-01\n",
      "   3.48971960e-02   4.34747516e-02   8.53492289e-02   1.70876642e-01\n",
      "   5.95735312e-01   9.54552584e-03   4.11726306e-01   2.93785639e-01\n",
      "   3.69078374e-01   1.55800201e-01   7.03559825e-02   9.84735862e-02\n",
      "   2.45158959e-01   4.55449648e-01   2.14830444e-01   3.48104646e-01]\n",
      "85\n",
      "[ 0.93344201  0.02707796  0.32631738  0.32631738]\n"
     ]
    }
   ],
   "source": [
    "if(n_perm!=0):\n",
    "#     countPermutations = np.zeros((snp_matrix.shape[1]), dtype=np.int)\n",
    "#     nBetterCorrelation = np.zeros((snp_matrix.shape[1]), dtype=np.int)\n",
    "    bestPermutationPval = np.ones((n_perm), dtype=np.float)\n",
    "    for perm in range(0,n_perm) :\n",
    "        LMM_perm = limix.qtl.qtl_test_lmm(snp_matrix, np.random.permutation(phenotype),K=kinship_mat,covs=cov_matrix)\n",
    "        #print(np.random.permutation(phenotype))\n",
    "        if(bestPermutationPval[perm] > min(LMM_perm.getPv()[0])):\n",
    "                bestPermutationPval[perm] = min(LMM_perm.getPv()[0])        \n",
    "#         print(bestPermutationPval[perm])\n",
    "#         for snp in range(0,len(LMM_perm.getPv()[0])):\n",
    "#             print(LMM_perm.getPv()[0][snp])\n",
    "#             countPermutations[snp]+=1;\n",
    "#             if(bestPermutationPval[perm]<=LMM.getPv()[0][snp]):\n",
    "#                 nBetterCorrelation[snp]+=1\n",
    "\n",
    "    #re-estimate P-value\n",
    "    print(bestPermutationPval)\n",
    "    print(LMM.getPv()[0])\n",
    "    #correctedPvalue(bestPermutationPval,LMM.getPv()[0])\n",
    "#     print(countPermutations)\n",
    "#     print(nBetterCorrelation)\n",
    "    #Here we need to take care of the permutation data/\n",
    "    #Relink phenotype to genotype (several options)\n",
    "    #Drop using speed ups from fastQTL.\n",
    "    #Calculate P-value using beta dist.\n",
    "\n",
    "   \n",
    "    \n",
    "# #add these results to qtl_results\n",
    "\n",
    "# temp_df = pd.DataFrame(index = range(len(snp_names)),columns=['feature_id','snp_id','p_value','beta','n_samples'])\n",
    "# temp_df['snp_id'] = snp_names\n",
    "# temp_df['feature_id'] = feature_id\n",
    "# temp_df['beta'] = LMM.getBetaSNP()[0]\n",
    "# temp_df['p_value'] = LMM.getPv()[0]\n",
    "# temp_df['n_samples'] = sum(~np.isnan(phenotype))\n",
    "# results_df = results_df.append(temp_df)\n",
    "# print(temp_df)\n",
    "# # output_writer.add_result_df(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
