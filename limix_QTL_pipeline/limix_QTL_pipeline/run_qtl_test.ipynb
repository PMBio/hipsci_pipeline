{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import limix\n",
    "import qtl_output\n",
    "import qtl_loader_utils\n",
    "from qtl_snp_qc import do_snp_qc\n",
    "import qtl_fdr_utilities\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import Imputer\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##loader functions\n",
    "# def _ensure_dir(file_path):\n",
    "#     '''Check if directory exists for output, and create it if it doesn't.'''\n",
    "#     directory = os.path.dirname(file_path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "# def _get_kinship_df(kinship_filename):\n",
    "#     if kinship_filename:\n",
    "#         kinship_df = pd.read_csv(kinship_filename,sep='\\t',index_col=0)\n",
    "#     else:\n",
    "#         kinship_df = None\n",
    "#     return kinship_df\n",
    "\n",
    "# def _get_samplemapping_df(sample_mapping_filename,sample_labels,key_from):\n",
    "#     assert(key_from in ['iid','sample'])\n",
    "#     if sample_mapping_filename:\n",
    "#         mapping_df = pd.read_csv(sample_mapping_filename,sep='\\t',header=None,names=['iid','sample'])\n",
    "#         mapping_df.set_index(key_from,inplace=True)\n",
    "#     else:\n",
    "#         #assume the mapping is the identity mapping\n",
    "#         identifiers = sample_labels\n",
    "#         mapping_df = pd.DataFrame(data=identifiers,index=identifiers,columns=['sample'])\n",
    "#     return mapping_df\n",
    "\n",
    "# def _get_covariate_df(covariates_filename):\n",
    "#     if covariates_filename:\n",
    "#         covariate_df = pd.read_csv(covariates_filename,sep='\\t',index_col=0)\n",
    "#     else:\n",
    "#         covariate_df = None\n",
    "#     return covariate_df\n",
    "\n",
    "# def _get_genotype_data(geno_prefix):\n",
    "#     bim,fam,bed = limix.io.read_plink(geno_prefix,verbose=False)\n",
    "#     fam.set_index('iid',inplace=True)\n",
    "#     return bim,fam,bed\n",
    "\n",
    "# def _get_annotation_df(anno_filename):\n",
    "#     annotation_col_dtypes = {'feature_id':np.object,\n",
    "#                          'gene_id':np.object,\n",
    "#                          'gene_name':np.object,\n",
    "#                          'chromosome':np.object,\n",
    "#                          'start':np.int64,\n",
    "#                          'end':np.int64,\n",
    "#                          'strand':np.object}\n",
    "#     annotation_df = pd.read_csv(anno_filename,sep='\\t',index_col=0,dtype=annotation_col_dtypes)\n",
    "#     return annotation_df\n",
    "\n",
    "# def _get_phenotype_df(pheno_filename):\n",
    "#     return pd.read_csv(pheno_filename,sep='\\t',index_col=0)\n",
    "\n",
    "# def do_snp_qc(snp_df, min_call_rate, min_maf, min_hwe_P):\n",
    "   \n",
    "#     #Determine call rate.\n",
    "#     call_rate = 1-snp_df.isnull().sum()/len(snp_df.index)\n",
    "#     #print(call_rate)\n",
    "#     #print(call_rate < min_call_rate)\n",
    "#     failed_snp_names  = list(snp_df.columns[call_rate < min_call_rate])\n",
    "#     #pass_qc_snps_all = list(snp_df.columns[call_rate >= min_call_rate])\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[call_rate >= min_call_rate])]\n",
    "\n",
    "#     #Determine MAF.\n",
    "#     genotypeCounter = np.zeros((len(snp_df.columns),3))\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         for sample in range(0, len(snp_df.index)):\n",
    "#             if not math.isnan(snp_df.iloc[sample,snp]) :\n",
    "#                 #print(snp_df.iloc[sample,snp])\n",
    "#                 #print(i)\n",
    "#                 #print(snp)\n",
    "#                 #print(int(round(snp_df.iloc[snp,i])))\n",
    "#                 genotypeCounter[snp,int(round(snp_df.iloc[sample,snp]))] +=1\n",
    "\n",
    "#     #Here we make sure that the major allele is temporarly \"coded\" as 0.\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         if genotypeCounter[snp,0]<genotypeCounter[snp,2]:\n",
    "#             tmp = genotypeCounter[snp,0]\n",
    "#             genotypeCounter[snp,0] = genotypeCounter[snp,2]\n",
    "#             genotypeCounter[snp,2] = tmp\n",
    "\n",
    "#     #print(genotypeCounter)\n",
    "#     maf = np.zeros((len(snp_df.columns)))\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         maf[snp] = ((genotypeCounter[snp,2]*2)+genotypeCounter[snp,1])/(len(snp_df.index)*2)\n",
    "\n",
    "#     failed_snp_names.extend(list(snp_df.columns[maf < min_maf]))\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[maf >= min_maf])]    \n",
    "#     genotypeCounter = genotypeCounter[maf >= min_maf,]\n",
    "\n",
    "#     #Determine HWE.\n",
    "#     hweP = np.zeros((len(snp_df.columns)))\n",
    "\n",
    "#     for snp in range(0, len(snp_df.columns)):\n",
    "#         rare_copies = int(((genotypeCounter[snp,2])*2)+genotypeCounter[snp,1])\n",
    "#         genotypes = (genotypeCounter[snp,2]+genotypeCounter[snp,1]+genotypeCounter[snp,0])\n",
    "#         het_probs = np.ones((rare_copies+1))\n",
    "#         # start at midpoint #\n",
    "\n",
    "#         mid = int(round(rare_copies * (2 * genotypes - rare_copies) / (2 * genotypes)))\n",
    "\n",
    "#         # check to ensure that midpoint and rare alleles have same parity #\n",
    "#         if mid % 2 is not rare_copies % 2 :\n",
    "#             mid+=1\n",
    "\n",
    "#         curr_homr = (rare_copies - mid) / 2;\n",
    "#         curr_homc = genotypes - mid - curr_homr;\n",
    "#         #print(mid)\n",
    "#         #print(het_probs.shape)\n",
    "#         sum_values = het_probs[mid];\n",
    "\n",
    "#         for curr_hets in range(mid, 2, -2) :\n",
    "#             het_probs[curr_hets - 2] = het_probs[curr_hets] * curr_hets * (curr_hets - 1.0) / (4.0 * (curr_homr + 1.0) * (curr_homc + 1.0))\n",
    "#             sum_values += het_probs[curr_hets - 2]\n",
    "#             ## 2 fewer heterozygotes for next iteration -> add one rare, one common homozygote ##\n",
    "#             curr_homr+=1\n",
    "#             curr_homc+=1\n",
    "\n",
    "\n",
    "#         curr_homr = (rare_copies - mid) / 2;\n",
    "#         curr_homc = genotypes - mid - curr_homr;\n",
    "#         for curr_hets in range(mid, (int(rare_copies) - 2), 2) :\n",
    "#             het_probs[curr_hets + 2] = het_probs[curr_hets] * 4.0 * curr_homr * curr_homc / ((curr_hets + 2.0) * (curr_hets + 1.0))\n",
    "#             sum_values += het_probs[curr_hets + 2]\n",
    "#             curr_homr-=1\n",
    "#             curr_homc-=1\n",
    "\n",
    "#         p_hwe = 0.0\n",
    "#         het_probs[int(genotypeCounter[snp,1])]/= sum_values\n",
    "#         for index in range(0,int(rare_copies)) :\n",
    "#             if index != int(genotypeCounter[snp,1]) :\n",
    "#                 het_probs[index] /= sum_values\n",
    "#             if het_probs[index] <= het_probs[int(genotypeCounter[snp,1])] :\n",
    "#                 p_hwe += het_probs[index];\n",
    "\n",
    "#         hweP[snp] = 1 if p_hwe > 1.0 else p_hwe;\n",
    "\n",
    "#     failed_snp_names.extend(list(snp_df.columns[hweP < min_hwe_P]))\n",
    "#     snp_df = snp_df.loc[:,list(snp_df.columns[hweP >= min_hwe_P])]\n",
    "\n",
    "#     return snp_df.columns, failed_snp_names\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#settings\n",
    "pheno_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_YRI_Expr.txt.gz'\n",
    "anno_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_Annot.txt'\n",
    "geno_prefix = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Genotypes/Geuvadis'\n",
    "window_size = 250000\n",
    "min_maf = 0.05\n",
    "min_hwe_P = 0.01\n",
    "min_call_rate = 0.95\n",
    "cis_mode = True\n",
    "# cis_mode = False\n",
    "n_perm=100\n",
    "snps_filename = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/snpFilterList.txt'\n",
    "output_dir = '/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/outputTest'\n",
    "chromosome='all'\n",
    "\n",
    "covariates_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Expression/Geuvadis_CEU_YRI_covariates.txt'\n",
    "kinship_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Genotypes/Geuvadis_chr1_kinship.txt'\n",
    "sample_mapping_filename='/hps/nobackup/stegle/users/mjbonder/tools/hipsci_pipeline/limix_QTL_pipeline/geuvadis_CEU_test_data/Geuvadis_CEU_gte.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core function to take input and run QTL tests on a given chromosome.\n",
    "#Load input data files & filter for relevant data\n",
    "\n",
    "bim,fam,bed = qtl_loader_utils.get_genotype_data(geno_prefix)\n",
    "phenotype_df = qtl_loader_utils.get_phenotype_df(pheno_filename)\n",
    "annotation_df = qtl_loader_utils.get_annotation_df(anno_filename)\n",
    "\n",
    "individual2sample_df = qtl_loader_utils.get_samplemapping_df(sample_mapping_filename,list(phenotype_df.columns),'iid')\n",
    "sample2individual_df = qtl_loader_utils.get_samplemapping_df(sample_mapping_filename,list(phenotype_df.columns),'sample')\n",
    "\n",
    "kinship_df = qtl_loader_utils.get_kinship_df(kinship_filename) \n",
    "if kinship_df is not None:\n",
    "    kinship_df = kinship_df.loc[list(set(fam.index)&set(individual2sample_df.index)),list(set(fam.index)&set(individual2sample_df.index))]\n",
    "    #Filter from individual2sample_df & sample2individual_df since we don't want to filter from the genotypes.\n",
    "    individual2sample_df = individual2sample_df.loc[kinship_df.index,:]\n",
    "    sample2individual_df = sample2individual_df[sample2individual_df['iid'].map(lambda x: x in list(map(str, kinship_df.index)))]\n",
    "    \n",
    "\n",
    "covariate_df = qtl_loader_utils.get_covariate_df(covariates_filename)\n",
    "phenotype_df = phenotype_df.loc[annotation_df.index.values,individual2sample_df.loc[list(set(fam.index)&set(individual2sample_df.index)),'sample'].values]\n",
    "if covariate_df is not None:\n",
    "    phenotype_df = phenotype_df.loc[:,covariate_df.index]\n",
    "    covariate_df = covariate_df.loc[phenotype_df.columns,:]\n",
    "snp_filter_df = qtl_loader_utils.get_snp_df(snps_filename)\n",
    "\n",
    "### make sure covariates, kinship & phenotype is not changed in a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSG00000215014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if(cis_mode):\n",
    "    #Remove features from the annotation that are on chromosomes which are not present anyway.\n",
    "    annotation_df = annotation_df[annotation_df['chromosome'].map(lambda x: x in list(set(bim['chrom'])))]\n",
    "    annotation_df = annotation_df[annotation_df['chromosome'].map(lambda x: x in list(map(str, range(1, 23))))]\n",
    "\n",
    "#Determine features to be tested\n",
    "if chromosome=='all':\n",
    "    feature_list = list(set(annotation_df.index)&set(phenotype_df.index))    \n",
    "else:\n",
    "    feature_list = list(set(annotation_df[annotation_df['chromosome']==chromosome].index)&set(phenotype_df.index))\n",
    "\n",
    "#Array to store indices of snps tested\n",
    "tested_snp_idxs = []\n",
    "\n",
    "feature_id = feature_list[1]\n",
    "print(feature_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1510355\n",
      "1511373\n",
      "(53, 7)\n",
      "22\n",
      "(0, 0)\n",
      "(90, 22)\n"
     ]
    }
   ],
   "source": [
    "chrom = str(annotation_df.loc[feature_id,'chromosome'])\n",
    "print(chrom)\n",
    "start = annotation_df.loc[feature_id,'start']\n",
    "print(start)\n",
    "end = annotation_df.loc[feature_id,'end']\n",
    "print(end)\n",
    "\n",
    "#make robust to features specified back-to-front\n",
    "lowest = min([start,end])\n",
    "highest = max([start,end])\n",
    "\n",
    "if (cis_mode) : \n",
    "    snpQuery = bim.query(\"chrom == '%s' & pos > %d & pos < %d\" % (chrom, lowest-window_size, highest+window_size))\n",
    "else :\n",
    "    snpQuery = bim.query(\"(chrom == '%s' & (pos < %d | pos > %d))|chrom != '%s'\" % (chrom, lowest-window_size, highest+window_size,chrom))\n",
    "    snpQuery = snpQuery.loc[snpQuery['chrom'].map(lambda x: x in list(map(str, range(1, 23))))]\n",
    "    \n",
    "blocksize = 500\n",
    "print(snpQuery.shape)\n",
    "if len(snpQuery) != 0 and snp_filter_df is not None:\n",
    "    snpQuery = snpQuery.loc[snpQuery['snp'].map(lambda x: x in list(map(str, snp_filter_df.index)))]\n",
    "    \n",
    "# print(len(snpQuery))\n",
    "if len(snpQuery) != 0:\n",
    "\n",
    "    print(len(snpQuery)%blocksize)\n",
    "    previous =0\n",
    "    results_df = pd.DataFrame()\n",
    "    print(results_df.shape)\n",
    "    for snpGroup in chunker(snpQuery, blocksize):\n",
    "        #Here we need to batch for cis & trans.\n",
    "        snp_idxs = snpGroup['i'].values\n",
    "        snp_names = snpGroup['snp'].values\n",
    "\n",
    "        tested_snp_idxs.extend(snp_idxs)\n",
    "\n",
    "        ##Check for NA's in feature. Remove samples with NA's\n",
    "\n",
    "        sample_ids = individual2sample_df.loc[:,'sample'].values\n",
    "\n",
    "        phenotype_ds = phenotype_df.loc[feature_id,sample_ids]\n",
    "        contains_missing_samples = any(phenotype_ds.isnull().values)\n",
    "        phenotype_ds.dropna(inplace=True)\n",
    "\n",
    "        #indices for relevant individuals in genotype matrix    \n",
    "        individual_ids = list(set(fam.index)&set(sample2individual_df.loc[phenotype_ds.index,'iid']))\n",
    "        individual_idxs = fam.loc[individual_ids,'i'].values\n",
    "\n",
    "        #subset genotype matrix, we cannot subselect at the same time, do in two steps.\n",
    "        snp_df = pd.DataFrame(data=bed[snp_idxs,:].compute().transpose(),index=fam.index,columns=snp_names)\n",
    "        snp_df = snp_df.loc[individual_ids,:]\n",
    "        print(snp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 22)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pass_qc_snps_all = []\n",
    "fail_qc_snps_all = []\n",
    "print(snp_df.shape)\n",
    "print(contains_missing_samples)\n",
    "\n",
    "#For the updated QC where we only use one individual per genotype. We can just select sites from df to test.\n",
    "if not contains_missing_samples:\n",
    "    #remove snps from snp_df if they fail QC\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[~snp_df.columns.isin(fail_qc_snps_all)]]\n",
    "    snps_to_test_df = snp_df.loc[:,snp_df.columns[~snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "    \n",
    "    #Only do QC on relevant SNPs. join pre-QCed list and new QCed list.\n",
    "    #passed_snp_names,failed_snp_names = snp_qc.do_snp_qc(snps_to_test_df)\n",
    "    #File will be called snp_qc.py\n",
    "    passed_snp_names,failed_snp_names = do_snp_qc(snps_to_test_df, min_call_rate, min_maf, min_hwe_P)\n",
    "    snps_to_test_df = None\n",
    "    \n",
    "    #append snp_names and failed_snp_names\n",
    "    pass_qc_snps_all.extend(passed_snp_names)\n",
    "    fail_qc_snps_all.extend(failed_snp_names)\n",
    "    \n",
    "    snp_names  = list(snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)])\n",
    "    #snp_names = ['snp_1_2739933', 'snp_1_2750437', 'snp_1_2752719', 'snp_1_2753372']\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "\n",
    "else:\n",
    "    #Do snp QC for relevant section.\n",
    "    passed_snp_names,failed_snp_names = do_snp_qc(snp_df, min_call_rate, min_maf, min_hwe_P)\n",
    "    snp_df = snp_df.loc[:,snp_df.columns[snp_df.columns.isin(pass_qc_snps_all)]]\n",
    "    \n",
    "    \n",
    "# if len(snp_df.columns) != 0:\n",
    "#     continue\n",
    "\n",
    "snp_matrix = snp_df.values\n",
    "snp_df = None\n",
    "\n",
    "snp_matrix = Imputer(missing_values=np.nan,strategy='mean',axis=0,copy=False).fit_transform(snp_matrix)\n",
    "\n",
    "if kinship_df is not None:\n",
    "    kinship_mat = kinship_df.loc[individual_ids,individual_ids].values\n",
    "else:\n",
    "    kinship_mat = None\n",
    "\n",
    "#map individual_ids to samples\n",
    "sample_ids = individual2sample_df.loc[individual_ids,'sample'].values\n",
    "phenotype = phenotype_ds.loc[sample_ids].values\n",
    "\n",
    "#generate covariate matrix\n",
    "if covariate_df is not None:\n",
    "    cov_matrix = np.concatenate([np.ones((len(sample_ids),1)),covariate_df.loc[sample_ids,:].values],axis=1)\n",
    "else:\n",
    "    cov_matrix = None\n",
    "\n",
    "#fit modelrun\n",
    "LMM = limix.qtl.qtl_test_lmm(snp_matrix, phenotype,K=kinship_mat,covs=cov_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.66084156e-01   6.39889818e-03   5.51441932e-04   5.59887018e-01\n",
      "   4.08577750e-01   3.22600005e-02   4.12118355e-01   1.63102317e-01\n",
      "   2.05920213e-02   1.42040405e-02   3.49483118e-02   4.39199775e-01\n",
      "   3.12932695e-03   4.73877357e-01   9.70293550e-02   1.15309069e-01\n",
      "   1.74780478e-02   2.28941582e-01   1.93194349e-02   4.29626661e-02\n",
      "   6.49407511e-02   1.68993585e-01   3.16254233e-02   1.05958190e-01\n",
      "   4.62165504e-01   6.07691630e-01   7.26003873e-01   3.49747795e-01\n",
      "   3.43561561e-01   5.21900931e-01   1.94752158e-01   2.92464186e-02\n",
      "   6.81695891e-02   3.44115862e-02   1.59159382e-01   3.31399175e-02\n",
      "   3.19401519e-01   1.12351388e-02   2.37799574e-01   2.80888339e-01\n",
      "   7.50042931e-04   9.51810862e-03   5.57042012e-01   1.72503708e-01\n",
      "   2.60412187e-01   3.17025268e-01   9.46765425e-02   4.45268749e-01\n",
      "   1.34256885e-01   5.18877765e-01   3.63718926e-02   3.18331250e-01\n",
      "   2.57874657e-01   3.72909586e-01   4.36837505e-01   3.65823548e-01\n",
      "   6.84793743e-02   2.28485692e-01   4.35113962e-02   3.29402874e-01\n",
      "   7.58300743e-02   3.17551956e-01   1.91387823e-02   6.61412073e-01\n",
      "   5.12241480e-02   1.27588694e-01   1.36949243e-01   4.11533775e-02\n",
      "   1.15638622e-01   3.66231463e-01   1.00755027e-01   5.12299369e-02\n",
      "   4.61649333e-02   1.37473803e-01   1.48461449e-02   7.14876871e-02\n",
      "   5.89766100e-03   2.50722284e-02   3.70619560e-02   8.22586532e-02\n",
      "   2.98309529e-01   2.13671944e-01   4.16521052e-02   2.57977681e-01\n",
      "   2.37806643e-01   7.50358858e-01   9.75594293e-02   7.15082153e-02\n",
      "   8.63051807e-02   1.54223697e-01   2.35427787e-01   3.38891948e-02\n",
      "   5.10935962e-03   1.86045173e-01   2.00925062e-01   7.86227187e-02\n",
      "   3.29666307e-02   4.77920080e-02   7.18240293e-02   2.78175577e-02]\n",
      "[ 0.93344201  0.02707796  0.32631738  0.32631738]\n",
      "[ 0.99979467  0.19062181  0.79529663  0.79529663]\n",
      "0.999794670309\n",
      "0.190621807627\n",
      "0.795296634366\n",
      "0.795296634366\n"
     ]
    }
   ],
   "source": [
    "if(n_perm!=0):\n",
    "#     countPermutations = np.zeros((snp_matrix.shape[1]), dtype=np.int)\n",
    "#     nBetterCorrelation = np.zeros((snp_matrix.shape[1]), dtype=np.int)\n",
    "    bestPermutationPval = np.ones((n_perm), dtype=np.float)\n",
    "    for perm in range(0,n_perm) :\n",
    "        LMM_perm = limix.qtl.qtl_test_lmm(snp_matrix, np.random.permutation(phenotype),K=kinship_mat,covs=cov_matrix)\n",
    "        #print(np.random.permutation(phenotype))\n",
    "        if(bestPermutationPval[perm] > min(LMM_perm.getPv()[0])):\n",
    "                bestPermutationPval[perm] = min(LMM_perm.getPv()[0])        \n",
    "#         print(bestPermutationPval[perm])\n",
    "#         for snp in range(0,len(LMM_perm.getPv()[0])):\n",
    "#             print(LMM_perm.getPv()[0][snp])\n",
    "#             countPermutations[snp]+=1;\n",
    "#             if(bestPermutationPval[perm]<=LMM.getPv()[0][snp]):\n",
    "#                 nBetterCorrelation[snp]+=1\n",
    "\n",
    "    #re-estimate P-value\n",
    "    print(bestPermutationPval)\n",
    "    print(LMM.getPv()[0])\n",
    "    corrected_pvalues = qtl_fdr_utilities.calculate_corrected_pvalues(bestPermutationPval,LMM.getPv()[0])\n",
    "    print(corrected_pvalues)\n",
    "#     print(countPermutations)\n",
    "#     print(nBetterCorrelation)\n",
    "    #Here we need to take care of the permutation data/\n",
    "    #Relink phenotype to genotype (several options)\n",
    "    #Drop using speed ups from fastQTL.\n",
    "    #Calculate P-value using beta dist.\n",
    "\n",
    "   \n",
    "    \n",
    "# #add these results to qtl_results\n",
    "\n",
    "temp_df = pd.DataFrame(index = range(len(snp_names)),columns=['feature_id','snp_id','p_value','beta','n_samples'])\n",
    "temp_df['snp_id'] = snp_names\n",
    "temp_df['feature_id'] = feature_id\n",
    "temp_df['beta'] = LMM.getBetaSNP()[0]\n",
    "temp_df['p_value'] = LMM.getPv()[0]\n",
    "temp_df['n_samples'] = sum(~np.isnan(phenotype))\n",
    "temp_df['corr_p_value'] = 1.0\n",
    "\n",
    "output_writer = qtl_output.hdf5_writer('test_out.h5')\n",
    "output_writer.add_result_df(temp_df)\n",
    "\n",
    "output_writer.apply_pval_correction(feature_id,bestPermutationPval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:limix_env]",
   "language": "python",
   "name": "conda-env-limix_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
